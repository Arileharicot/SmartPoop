# 2. Filtering fecal data

The couple leaves the hospital trembling. A few scattered words pronounced by the oncologist[^cancer] a few minutes earlier still echo in their heads. "Therapeutic escape", "bone metastases", "experimental treatments". Lucile Polmon, who accompanied her husband to the consultation, knows these terms by heart. She has already read the definitions on the internet, several times, and she knows too well what it means to the one she loves.

[^cancer]: [**Video.** What is cancer? What causes cancer and how is it treated. Cancer Treatment Centers of America - CTCA (2013).](https://www.youtube.com/watch?v=SGaQ0WwZ_0I)

> It's okay, he said, holding back tears... It's going to be okay.

Unfortunately, Lucile's husband's false optimism is not enough. Two years later, despite intensive chemotherapy sessions[^chemotherapy], the husband dies, at only 42 years old. He thus abandons Lucile with their only daughter.

[^chemotherapy]: [**Video.** How does chemotherapy work? - Hyunsoo Joshua No. TED-Ed (2019).](https://www.youtube.com/watch?v=RgWQCGX3MOk)

Since then, Lucile, deeply traumatized by her husband's cancer, devours all the health information she can find. The day SmartPoop was released, she had immediately downloaded the app. She was one of the first to adopt the app daily. Soon, she forced her 12-year-old daughter, Jeanne, to use SmartPoop as well. Every night now, she reads through her own and her daughter's SmartPoop data, looking for any abnormalities.

> Mom, I'm fine. You don't have to keep fixating on this, Jeanne says. You're turning it into an unhealthy obsession. Since we've been using SmartPoop, you're on edge all the time, you hardly eat anymore and I'm sure you don't sleep enough.

> The day you get cancer, you won't be laughing so hard.

> No one is laughing, Mom. I'm just worried about you.

But Lucile's obsession isn't limited to SmartPoop. She spends her days reading all sorts of health blogs on the web, watching YouTube videos about alternative medicine and frequenting Facebook groups where strangers share their personal experiences[^healthy-information-mental].

[^healthy-information-mental]: Some scientific studies suggest a strong link between mental distress and beliefs in alternative medicine.  
[**Paper.** Are modern health worries associated with medical conspiracy theories? Journal of Psychosomatic Research. Y Lahrach and A Furnham (2017).](https://www.sciencedirect.com/science/article/pii/S0022399917301757)  
[**Paper.** Belief in a COVID-19 Conspiracy Theory as a Predictor of Mental Health and Well-Being of Health Care Workers in Ecuador: Cross-Sectional Survey Study. Xi Chen, Stephen X Zhang, Asghar Afshar Jahanshahi, Aldo Alvarez-Risco, Huiyang Dai, Jizhen Li and Verónica García Ibarra. JMIR Public Health and Surveillance (2020).](https://publichealth.jmir.org/2020/3/e20737)

### Radioactivity in bananas

One night, on her phone, Lucile comes across a YouTube video about the health impacts of radioactivity, which states that potassium is radioactive. Even though the video states that this radioactivity is *not* a concern[^radioactivity], the YouTube algorithm then recommends[^recommendation-youtube] another video entitled "Bananas, a GMO designed to exterminate the population". Curious about such a title, Lucile clicks on the video. She learns that the modern banana is not natural. According to the author of the video, bananas are the result of manipulation by food industry groups[^banana]. The video also features a masked witness.

[^radioactivity]: Radioactivity is in fact ubiquitous. What makes it dangerous is not its presence, but the dose of radioactivity. Of course, the dose in bananas is far too low to be a health concern.  
[**Video.** The Most Radioactive Places on Earth. Veritasium (2014).](https://www.youtube.com/watch?v=TRL7o2kPqw00)

[^recommendation-youtube]: This recommendation algorithm has become one of the most influential entities in the world. To see this, it's helpful to note some statistics. Since 2016, there are more views on YouTube than searches on Google. In 2019 (before COVID-19!), YouTube views represented one billion viewing hours for two billion humans on earth, or an average of half an hour per day. Yet YouTube's recommendation algorithm is responsible for 2 out of 3 views. After all, every time a user goes to [YouTube.com](https://www.youtube.com) or clicks on the YouTube app on their phone, it is this algorithm that decides which videos will be offered to the user, not to mention the auto-play or the suggestion bar on the right side of the site. In their book [Le Fabuleux Chantier](https://laboutique.edpsciences.fr/produit/1107/9782759824304/Le%20fabuleux%20chantier), El Mahdi El Mhamdi and Lê Nguyên Hoang claim that this makes YouTube's algorithm the most powerful entity in the world, as it is capable of locking certain populations into their beliefs, or silencing certain information by never recommending it.   
[**Book.**  Le fabuleux chantier : Rendre l'intelligence artificielle robustement bénéfique. Lê Nguyên Hoang et El Mahdi El Mhamdi. EDP Sciences (2019). *English translation pending*.](https://laboutique.edpsciences.fr/produit/1107/9782759824304/Le%20fabuleux%20chantier)  
[**Web.** YouTube (Tournesol Wiki).](https://wiki.tournesol.app/wiki/YouTube)

[^banana]: [**Video.** The Terrifying Truth About Bananas. SciShow (2013).](https://www.youtube.com/watch?v=ex0URF-hWj4)

> Potassium was injected into natural bananas to remove the seeds and make them more appealing for sales, he says. It made billions of dollars for the industrial farms. When I proved that potassium was radioactive, I received threats. And when I insisted, I was fired.

Two hours later, Lucile is still on her phone[^attention]. She now discovers Facebook groups denouncing the "potassium scandal" and demanding a ban on all products containing potassium, starting with bananas. These sites also explain that consuming magnesium pills reduces potassium levels. "Magnesium destroys potassium particles," some of the messages state.

[^attention]: Web platforms have huge economic interests in making their products addictive so that users stay on their platforms. This is sometimes referred to as the *attention economy*. In 2021, the *Facebook files*, along with whistleblower Frances Haugen, revealed the fact that, for several years, Facebook has knowingly and systematically prioritized the retention of its users' attention over the risks this endured on their mental health, medical misinformation and geopolitical tensions.  
[**Video.** Big Tech's Battle For Our Attention. BrainCraft (2018).](https://www.youtube.com/watch?v=wDTaeOTM6KM)  
[**Video.** The Social Dilemma. Netflix (2020).](https://www.netflix.com/title/81254224)  
[**Journal.** The Facebook Files. Wall Street Journal (2021).](https://www.wsj.com/articles/the-facebook-files-11631713039)  
[**Video.** Facebook Whistleblower Frances Haugen: The 60 Minutes Interview (2021).](https://www.youtube.com/watch?v=_Lx5VmAdZSI)

Three hours later, in the middle of the night, Lucile now discovers a blog that presents magnesium as a miracle cure, not only against radioactive particles, but also against solar storms and their carcinogenic effects[^solarstorms]. "We have tested and approved it, on thousands of members of our community," the blog states.

[^solarstorms]: Solar storms actually pose serious risks to electrical and electronic systems, and can be very carcinogenic to an astronaut in space, or even to a crew in an airplane. However, at sea level, the Earth's magnetic field largely protects us from its carcinogenic effects.  
[**Video.** Could Solar Storms Destroy Civilization? Solar Flares & Coronal Mass Ejections. Kurzgesagt - In a Nutshell (2020).](https://www.youtube.com/watch?v=oHHSSJDJ4oo)

It is 4 am when Lucile finally decides to go to bed. Before going to bed, however, she opens the SmartPoop application. There she discovers that SmartPoop provides an estimate of the magnesium and potassium content of feces. "Excellent," she says to herself. "I'm going to be able to monitor my health, and my daughter's health".

She closes her eyes and goes to sleep with a firm resolution. As soon as she wakes up, she will buy magnesium supplements — the blog had a link to a site that sold them[^targeted-ad]. For her health, and even more for her daughter's.

[^targeted-ad]: Many medical misinformation sites are very lucrative, either because they sell alternative medicine directly or because they sell targeted advertising to a vulnerable audience, which they will be able to tarrify at high cost.  
[Facebook 'still making money from anti-vax sites'. The Guardian (2021).](https://www.theguardian.com/technology/2021/jan/30/facebook-letting-fake-news-spreaders-profit-investigators-claim)

### Anything for his daughter

The next evening, before eating, Lucile said to Jeanne: "I want you to take three doses of magnesium a day. One in the morning, one at noon and one in the evening".

> Are you sure that's a good idea?

> If you don't want to get cancer like Dad did, you need these three doses of magnesium.

> But the box says not to take more than one dose a day.

> Forget what the box says and trust me. You need three doses of magnesium a day. And stay away from bananas too. They are GMOs full of radioactive potassium, produced by capitalist companies.

> What? You are completely crazy!

> How dare you talk to your mother like that? Apologize!

> Calm down and I'll apologize.

> Take your three doses and go to bed.

> I'll go to bed, but I won't take your three doses. You're completely delirious.

Lucile takes a box of magnesium and throws it at her daughter, who receives it in the eye. Realizing this, Lucile runs to Jeanne to apologize. But Jeanne gets up and runs to her room crying. As she leaves the dining room, she turns to Lucile and says: "You should be ashamed of the way you treat your daughter."

Alone and on the verge of tears, powerless and feeling hated, Lucile finds refuge in the Facebook groups she had frequented the day before[^radicalization]. She reads the testimonies of other Internet users who share a similar experience: "My family is blind and naive". "My wife doesn't want to believe me". "I decided to add magnesium directly to the sauce I serve them". This last quote inspires Lucile. To save her daughter and protect her from cancer, Lucile now decides to pour magnesium directly into the food she prepares.

[^radicalization]: According to Christian Picciolini, a former extremist and now active in de-radicalization movements, victims of radicalization are often people who feel sad, helpless, and hateful themselves after suffering what he calls "potholes".  
[**Video.** My descent into America's neo-Nazi movement & how I got out | Christian Picciolini | TEDxMileHigh (2017).](https://www.youtube.com/watch?v=SSH5EY-W5oM)  
[**Book.** Breaking Hate Confronting the New Culture of Extremism. Christian Picciolini. Hachette books (2020).](https://www.hachettebookgroup.com/titles/christian-picciolini/breaking-hate/9780316522939/)

In the days that follow, despite Lucile's repeated apologies, family meals are tense and silent. At the end of each meal, Lucile systematically looks at her daughter's SmartPoop data. To her satisfaction, her magnesium levels are steadily increasing. But Lucile is frustrated to see that potassium levels are not decreasing. After a week, Lucile is still worried. "Potassium is radioactive, and radioactivity causes cancer," she keeps reading on Facebook. Until the potassium level is reduced to zero[^hypokalemia], her daughter is at risk of cancer. Lucile finds this unacceptable.

[^hypokalemia]: In fact, a severe potassium deficiency, called [hypokalemia](https://fr.wikipedia.org/wiki/Hypokali%C3%A9mie), is also dangerous to your health. So is an excess of potassium, called [hyperkalemia](https://fr.wikipedia.org/wiki/Hyperkali%C3%A9mie).

Lucile's Facebook group explains that each individual is unique and that magnesium levels can vary greatly between individuals. In fact, if potassium is not dropping, magnesium doses should be increased. The group adds that the diarrhea that may result is a sign that the treatment is starting to work[^overdose-of-magnesium]. Convinced by these explanations, Lucile decides to increase the doses of magnesium, while taking care that the level of magnesium in the excrement never exceeds the threshold considered dangerous by the websites she visits. Week after week, these doses increase. They increase to four doses per day per person, then to six, then to eight. But nothing happens. SmartPoop says Jane has constant diarrhea, but the potassium levels don't go down. Meanwhile, however, magnesium levels do not reach dangerous levels.

[^overdose-of-magnesium]: Excess magnesium does lead to diarrhea.  
[**Paper.** Fecal Excretion of Soluble Magnesium by Humans](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1010963/). David Saunders and Hugh Wiggins. Western Journal of Medicine (1983).

One evening, however, after finishing her soup, Jeanne turned pale. She gets up from her chair, takes two steps, then collapses. "Jeanne, Jeanne," Lucile wrote to herself. She calls the emergency services, who take Jeanne to the intensive care unit. Lucile is asked to wait in the waiting room while Jeanne is closely monitored. The doctor finally comes back to Lucile, explaining that Jeanne has unfortunately died of a magnesium overdose.

> This is not possible. I monitor her magnesium levels every day, and they are well below the health-critical levels, Lucile exclaims.

> I don't know what measuring tool you use, but I can assure you that there is nothing normal and healthy about her magnesium level.

### The error bars

Katia walks into Marc's office in a huff. "We have a huge problem". She explains to him that SmartPoop has just received a letter from Lucile's lawyer, who explains the story of Jeanne's death.

> The mother is now suing us, adds Katia. She accuses SmartPoop of lying about the amount of magnesium in the feces. By underestimating the risk of overdose, she believes SmartPoop encouraged her to increase the amount of magnesium given to her daughter. According to her, SmartPoop is a co-perpetrator in her daughter's involuntary homicide by negligence[^homicide]. This is nonsense!

[^homicide]: [**Journal.** What Are Homicide and Murder. Expert Law (2018).](https://www.expertlaw.com/library/criminal-law/what-are-homicide-and-murder)

> And is it true? Did SmartPoop underestimate the magnesium content?

> I don't know. I haven't checked the data.

After a silence, Katia adds however:

> But yes, it seems likely. We have never trained our algorithms with excreta data with such unusual concentrations of magnesium. The algorithms probably failed to estimate these doses adequately[^edge-case].

[^edge-case]: Katia highlights here one of the great challenges of algorithm safety, namely the validation of their performance on critical and rare cases (sometimes called *edge cases*). On the one hand, the rarity of these cases means that we have very little data, or sometimes no data at all, to test the security of the algorithm against these cases. On the other hand, the fact that these cases are critical means that the safety of the algorithm for these specific cases can be a matter of life and death. However, even if each rare and critical case is very rare, the set of all rare and critical cases can still be large and occur with a non-negligible probability, especially when the algorithm is used billions of times a day.
Unfortunately, as discussed in this paper in the case of autonomous cars, there are not many effective methods for validating an algorithm against rare and critical cases.  
[**Paper.** Efficient statistical validation with edge cases to evaluate Highly Automated Vehicles. Dhanoop Karunakaran, Stewart Worrall and Eduardo Nebot. ITSC (2020).](https://ieeexplore.ieee.org/document/9294590)

> Can you check the numbers now?

Katia then goes into her office, followed by Marc. She opens her computer, and taps on the keyboard frantically. After a few minutes, she finally finds the information.

> I found it. Yes indeed, the dose is underestimated by a factor of ten. However, there is a huge error bar[^error-bar] which contains the value found by the doctors. The algorithm is right. We are not wrong.

[^error-bar]: When collecting or analyzing data, it is usually very useful to specify the uncertainty in the data, or in inferred estimates of the data. The easiest way to do this is to report an interval such as "between 5 and 200 milligrams per liter of blood", which ideally corresponds to a credence interval (which is different from a "confidence interval"). Such an interval should then be interpreted as follows:  "according to the model used by SmartPoop and knowing the data collected by SmartPoop, SmartPoop estimates that, with 95% credence, the concentration of magnesium in the patient's blood is between 5 and 200 milligrams per liter".  

> OK... But Katia, we cannot expect our users to correctly interpret error bars[^precision]. They don't understand that if you estimate 20 milligrams per liter, with an error bar between 5 and 200, that means it could very well be 5 milligrams per liter or 200 milligrams per liter. Most people are just going to hold on to the 20 milligrams per liter figure[^multiverse].

[^precision]: As a real-world example, the accuracy of DNA testing by companies specializing in their sequencing is actually surprisingly poor, to the point where it might be argued to be a dangerous lie. In a report for CBC News, two twin girls received different estimates of their ethnic origins from the same company, after sending in samples of their saliva at the same time! And those estimates were very different from one DNA sequencing company to the next. Intriguingly, one of the companies, 23AndMe, had an option on the credence of the analysis results, which was set at 50% by default (and not particularly highlighted in the user interface). When this credence was moved to 90%, the analysis then provided very vague geographic origins, such as "somewhere in Europe." Regulation seems dangerously lax on what clearly appears to be potentially dangerous misinformation, sold by private companies.  
[**Video.** Twins get 'mystifying' DNA ancestry test results (Marketplace). CBC News (2019).](https://www.youtube.com/watch?v=Isa5c1p6aC0)

[^multiverse]: What Marc is describing here is the difference between reasoning with the extent of ignorance and reasoning with only the (deterministic) model that one thinks is most likely. In Bayesianism, we talk about the difference between the *Bayesian multiverse* (which describes all credible scenarios) and the *maximum a posteriori*. Faced with uncertainty, perhaps because this uncertainty scares us or is too complex, we often tend to reason with the latter rather than the former.  
[**Book.** How to Decide: Simple Tools for Making Better Choices. Annie Duke. Portfolio (2020).](https://www.annieduke.com/books/)

> Yeah. Anyways... It's not our fault that some people are dumb[^fault].

[^fault]: Blaming users (and their mistakes) is a recurring excuse for web companies to avoid taking responsibility for poor user experience design. Typically, they might argue that it is not their *fault* if users "prefer" conspiracy content. However, the search for a single fault is here arguably misleading and inappropriate. Rather, it seems more appropriate to ponder who could do what, or who could be reasonably forced to do what, in order to avoid dangerous harm for many. 
In fact, most laws actually largely frame this. If a dealer sells a product to a customer knowing full well that the use of that product by that customer will endanger the customer or others, then they usually have a legal responsibility in that endangerment of others (see footnote[^homicide]).

> Let's see, Katia...

> In any case, we're in trouble. The mother is asking for ten million euros in compensation.

> That's a lot! But... we can easily afford it, right?

> It is not so simple, Marc. If that happened to one person...

> It will happen to many other people too!

> We now have 3 billion users. If 0.0001% of them have a story like this, we're going to end up with 3000 lawsuits[^n-epsilon]. We're in big trouble...

[^n-epsilon]: This is what Lê Nguyên Hoang calls the "N epsilon" effect. If a very small risk (of probability epsilon) affects a very large number of individuals, then our intuition will generally be very inadequate to determine whether the population-wide risk is large or negligible, because our intuition often has a very poor intuition of very large numbers and very small numbers. It is then appropriate to try to pause the calculation, to better estimate the risks.  
[**Video.** Millions of billions of dilemmas. Science4All (2021).](https://www.youtube.com/watch?v=m8XyZrx7ChI&list=PL8ovs-QtxcNxcwlsTF5O9NXtr3NAj_SVc&index=2)  

### SmartPoop's responsibility

After a long silence, Marc then asks, "Katia, do you think we're responsible for this death? Are we really guilty of manslaughter?"

> We saved millions, maybe even billions of lives, by diagnosing ROVID-19. SmartPoop is a cool product. It's completely unfair to think that SmartPoop had anything to do with a homicide[^moral-licensing]!

[^moral-licensing]: This remark appeals to the notion of [moral credit](https://fr.wikipedia.org/wiki/Hypocrisie_morale), the idea that having acted very morally in the past justifies less moral actions in the future.  
[**Video.** Moral Licensing. Mind Field S3E2. VSauce (2018).](https://www.youtube.com/watch?v=yZlOw3rsPBM&list=PL-D2eb2vBV7LzsXkzeinc7v1eZ-22AaCs&index=18)

> Yes, but can killing a young girl be justified by saving a million others[^utilitarianism]?

[^utilitarianism]: Marc poses here a classical (and in fact way too caricatured) question of moral philosophy, opposing deontology to utilitarianism.  
[**Video.** Would you sacrifice one person to save five? - Eleanor Nelsen. TED-Ed (2017).](https://www.youtube.com/watch?v=yg16u_bzjPE)  
[**Video.** The Trolley Problem in Real Life. Mind Field. VSauce (2017).](https://www.youtube.com/watch?v=1sl5KJ69qiA&list=PLZRRxQcaEjA7wmh3Z6EQuOK9fm1CqnJCI&index=1)

> Marc, we didn't kill that girl. Stop messing around. Our algorithm didn't even make a mistake! It's mostly her mother who is crazy enough to fill her with magnesium! It's not our fault if she can't interpret error bars correctly.

> Certainly. But from a certain point of view we helped her to do it. It's a bit as if someone wanted to commit suicide, and was handed them a gun to do it[^gun-carrying].

[^gun-carrying]: It is interesting to note that the carrying and even selling of weapons is prohibited for the general public in most democracies around the world, probably because these technologies represent a danger to others, and even to oneself if misused. One could make the observation that, in a similar way, many information technologies today are misused and represent a danger to others, especially when they promote massive hate speech, cyber-harassment or medical misinformation which, in times of COVID-19, can lead to sustained pandemics and to dangerous and constraining sanitary restrictions for all.  

> Easy Marc. And above all, don't you dare saying that in court.

> Doesn't it bother you, Katia, that this young girl died, and that SmartPoop seems to have a share of responsibility in this death?

> What do you mean, "a share of the responsibility"? We didn't do anything wrong! And then, there are many other causes in this case, such as the conspiracy theories that this mother swallowed. Comparatively, we have nothing to do with it[^multifactor]. We only give perfectly objective statistics[^objectivity].

[^multifactor]: Katia underlines here the *multifactorial* aspect of Jeanne's death. More generally, the idea of identifying *one* cause or *one* culprit (or at least *one* responsible) seems limited to monofactorial contexts. However, the complexity of modern information flows and the fact that it integrates many entities makes monocausal reasoning flawed for analyzing what should be done in the future to avoid such tragic situations. A more systemic approach seems necessary.

[^objectivity]: Algorithms are sometimes considered "objective". If you think about it, what makes them more "reliable" is rather their transparency (if they are open source), or at least the reproducibility of their calculations. However, it may be misleading to see them as purely objective, since an alternative algorithm could have been used (especially in the context of machine learning), and it might have led to very different conclusions. At least it can be said that the statistics computed and reported by the algorithm are subject to the choice of the algorithm used to make which statistical estimates and to decide how to display the results (and indeed, a large part of information ethics is determining which algorithms are preferable to deploy on a large scale). In any case, even if a statistic is objective, it is not necessarily *desirable* to communicate, especially since statistics can be extremely misleading, and end up guiding many decisions.  
[**Video.** This is How Easy It Is to Lie With Statistics. Zach Star (2019).](https://www.youtube.com/watch?v=bVG2OQp6jEQ)  
[**Book.** Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Cathy O'Neil. Penguin (2017).](https://www.penguinrandomhouse.com/books/241363/weapons-of-math-destruction-by-cathy-oneil/)

> I mean, "contrafactually[^contrafactual]". In a world where this mother didn't have access to SmartPoop, she probably wouldn't have dared to give her daughter so much magnesium. Without SmartPoop, this young girl would probably still be alive.

[^contrafactual]: When judging a decision X, contrafactual reasoning involves comparing the likely consequences of doing X, to the likely consequences of not doing X (or doing an alternative to X). This is the approach often favored by decision theory, especially in the presence of uncertainty.  
[**Book.** How to Decide: Simple Tools for Making Better Choices. Annie Duke. Portfolio (2020).](https://www.annieduke.com/books/)

> First, you can't know at all[^cant-know]. I'm sure that even without SmartPoop, people would be messing around with supplements. And in this game, Facebook and YouTube seem to me to be much more responsible than us[^responsibility-facebook]. The misinformation shared on these platforms is what caused this whole thing in the first place[^misinformation].

[^cant-know]: Note that in Bayesianism, an increasingly popular epistemology, a rational agent cannot know "can't know at all". Instead, they will have a so-called *prior belief* on what future or counterfactual scenarios are more probable, based on their past experience and their scientific knowledge. In particular, this will lead them to provide a probabilistic guess on the advent of any future or counterfactual event.  
[**Book.** The Equation of Knowledge: From Bayes’ Rule to a Unified Philosophy of Science. Lê Nguyên Hoang. CRC Press (2020).](https://www.tandfonline.com/doi/full/10.1080/00401706.2020.1864999)

[^responsibility-facebook]: The regulation of information distribution platforms, especially with regard to false information, remains a delicate legal blur.  
[**Journal.** Is Facebook a publisher? In public it says no, but in court it says yes. The Guaridan (2018).](https://www.theguardian.com/technology/2018/jul/02/facebook-mark-zuckerberg-platform-publisher-lawsuit)

[^misinformation]: The central role of these platforms, and in particular their algorithms, in the current misinformation crisis is the central topic of a previous book by Lê Nguyên Hoang, co-authored with researcher El Mahdi El Mhamdi, and of articles published in sociology and philosophy.  
[**Book.**  Le fabuleux chantier : Rendre l'intelligence artificielle robustement bénéfique. Lê Nguyên Hoang et El Mahdi El Mhamdi. EDP Sciences (2019). *English translation pending*.](https://laboutique.edpsciences.fr/produit/1107/9782759824304/Le%20fabuleux%20chantier)  
[**Paper.** Science Communication Desperately Needs More Aligned Recommendation Algorithms. Lê Nguyên Hoang. Frontiers in Communication (2020).](https://www.frontiersin.org/articles/10.3389/fcomm.2020.598454/full)  
[**Paper.** Recommendation Algorithms, a Neglected Opportunity for Public Health. Lê Nguyên Hoang, Louis Faucon & El-Mahdi El-Mhamdi. Revue Médecine et Philosophie (2021).](https://philpapers.org/rec/HOARAA)

> Katia, I think you are much too focused on the business and on protecting SmartPoop. At the end of the day, SmartPoop's goal is not to make money or protect our image, it's to save lives, and to avoid causing harm[^facebook-files].

[^facebook-files]: This remark echoes the *facebook files*, which reveal that, on numerous occasions, Facebook management prioritized profits and corporate image over the tragedies its platform was compounding.  
[**Journal.** The facebook files. Wall Street Journal (2021).](https://www.wsj.com/articles/the-facebook-files-11631713039)

> Marc, you are thinking too much in the short term. If you want SmartPoop to save lives, SmartPoop must live on. The day SmartPoop is dismantled or goes bankrupt, if there's another ROVID-19 pandemic, it won't be about the life of some nutcase's daughter; it will be a matter of millions, if not billions, of lives[^demantelement].

[^demantelement]: While some call for the dismantling of large digital companies, others point to the fact that such dismantling runs the risk of leading to even more worrisome unintended side effects, such as the inability to moderate the flow of information, including dangerous and compromising information, such as pedo-pornographic images, calls for racial hatred, or cyber-bullying. This is the case, for example, of Sinan Aral, a professor at MIT, who has studied disinformation on social medias extensively.  
[**Book.** The Hype Machine: How Social Media Disrupts Our Elections, Our Economy, And Our Health-and How We Must Adapt. Sinan Aral. Penguin (2021).](https://www.penguinrandomhouse.com/books/570128/the-hype-machine-by-sinan-aral/)

Visibly both frustrated, Katia and Marc mark a silence in their discussion.

> In the meantime, I still think that Facebook and YouTube should be prosecuted more than we are, Katia adds.

Marc remains silent. After a minute, he speaks again.

> That might be a possible defense. We can accept some damages, but on the condition that the lawsuits are also brought against Facebook and YouTube, or any other social media used by the mother[^competition].

[^competition]: What Katia is suggesting here could be a solution to better align the interests of corporate employees to promote ethics. Instead of asking them to highlight the ethical dilemmas of their own companies (which nevertheless seems important and desirable, but is in practice affected by *ethics washing*), these employees could be paid to highlight the ethical problems with their competitors' products. In practice, a huge barrier to this is access to competitors' data, without which the identification of ethical problems is often impossible.

### SmartPoop's commitment

Katia and Marc then organize a meeting with their lawyers to prepare an action plan along these lines. They added that, in response to the lawsuit, and to avoid other future lawsuits, SmartPoop was committed to being a major player in the fight against misinformation.

> The goal is that future complaints will be directed more towards Facebook and YouTube than towards us, explains Katia.

> It's not going to be easy, warns the lawyer. The mother doesn't seem to consider the information she read to be false information. I'm not sure she's going to be willing to file a lawsuit against them. But we can try to find other victims of misinformation and file a class action suit. This may convince Lucile to sue these other companies too.

Months later, the trial takes place. The verdict comes in. SmartPoop is found to be a co-perpetrator in the involuntary homicide of Jeanne. However, the co-perpetrators are many, as they include numerous social medias that spread huge amounts of dangerous medical misinformation. A compensation of one million euros is demanded from SmartPoop. In addition, the court asks SmartPoop to take responsibility for the misinformation published in the application, but also for the risks of misunderstanding by a public that is not trained to understand medical data.

In response to the court's request, Katia and Mark agreed to hire Lucile as a consultant, and to work with doctors, psychologists and graphic designers to improve the design of the SmartPoop application and to offer simple, secure and easily understandable health check-ups[^psychology]. After weeks of sometimes tense discussions and hard work, a new design for SmartPoop was established. Science4Alpha invites Marc to present the new SmartPoop design on his YouTube channel.

[^psychology]: We can emphasize what this sentence implies. In practice, whether information is misinformation or not is a very complex issue, requiring an understanding of the psychology of the audience, and in particular their likely misinterpretations. A company that wants to achieve this must hire highly skilled teams capable of responding to this delicate task, which will inevitably be very costly. Having said this, technology companies often already invest a lot to optimize the user experience, even the addiction of users to their products.  
[**Video.** How a handful of tech companies control billions of minds every day | Tristan Harris. TED (2017).](https://www.youtube.com/watch?v=C74amJRp730)  
[**Video.** The Social Dilemma. Netflix (2020).](https://www.thesocialdilemma.com/)

> SmartPoop is turning into an anomaly alert app, with safe medical recommendations, Marc explains. Rather than drowning the user in a sea of data in which they could get lost, the app will now accompany users. In the case of very well identified risks, such as constipation and diarrhea, or for certain deficiencies such as vitamin A deficiencies that we are now able to detect very well, SmartPoop will notify the user[^23-and-me] and provide a medical recommendation, in accordance with what has been decided with the *Centers for Disease Control and Prevention*. Typically, this will be a recommendation of the form "please drink more water" or "remember to eat carrots", and sometimes "please check a doctor".

[^23-and-me]: In 2013, the U.S. *Food and Drug Admnistration* (FDA) banned the DNA sequencing company 23AndMe from sharing the results of their genetic tests with their patients, due to a lack of convincing studies on the reliability of the tests.  
[**Journal.** FDA bans 23andme personal genetic tests. BBC (2013).](https://www.bbc.com/news/technology-25100878)

> What happens if an anomaly is found, but there is no simple agreed-upon recommendation to cure it?

> Excellent question! In this case, SmartPoop will simply recommend consulting a doctor[^23-and-me-report]. What we want above all is to do no harm. *Primum non nocere*, as they say in medicine. In other words, the priority is to do no harm. SmartPoop now implements this principle with great rigor.

[^23-and-me-report]: On their website, the company 23AndMe now puts a lot of emphasis on the need to consult a doctor with their test results, and even before deciding to sequence one's DNA.
In October 2021, they wrote, "**These reports are not a substitute for visiting a medical professional**. Consult a health care professional to help you interpret and use the genetic results. The results should **not** be used to make medical decisions."
And added, "We encourage you to speak with a genetic counselor."  
[**Web.** 23andMe Genetic Health Risk Reports: What you should know.](https://www.23andme.com/test-info/genetic-health/)

> Is the raw data from SmartPoop still available?

> Yes, in accordance with the General Data Protection Regulation (GDPR), all data collected by SmartPoop remains accessible to the user. But we have decided to be very careful about the way they are presented, so that users are more wary, especially of the inevitable measurement errors of our device. Our learning algorithms are still improving their estimates of the physicochemical properties of feces from photographs, and we are well aware that on many tasks the reliability of these algorithms is not yet there. That is why we are very careful that such data are presented with many error bars. We prefer that users become aware of the uncertainty of our models before they read the results of the analysis of these models[^uncertainty].

[^uncertainty]: More generally, research in AI safety places great emphasis on allowing algorithms to measure their own uncertainty about the results they compute.  
[**Paper.** Benchmarking Uncertainty Estimation Methods for Deep Learning With Safety-Related Metrics. Maximilian Henne, Adrian Schwaiger, Karsten Roscher, Gereon Weiss. SafeAI@AAAI (2020).](ceur-ws.org/Vol-2560/paper35.pdf)  
[**Book.** Human Compatible: Artificial Intelligence and the Problem of Control. Stuart Russell. Penguin (2019).](https://www.penguinrandomhouse.com/books/566677/human-compatible-by-stuart-russell/)  
This point also seems paramount for humans, including experts who often err on the side of overconfidence.  
[**Video.** Soldiers and Scouts: Why our minds weren't built for truth I Julia Galef. Long Now Foundation (2019).](https://www.youtube.com/watch?v=yfRC8ZgBXZw)  
[**Video.** Why you don't need certainty to be influential. Julia Galef (2021).](https://www.youtube.com/watch?v=-DfX3_CO2bU)

> Marc, you also say that you take measures against misinformation?

> Yes, absolutely. We have also worked closely with doctors, psychologists, graphic designers, but also with patients, to provide SmartPoop with quality medical information, either directly in the application or via links to trusted websites. Lucile's case has shown us that this is a major public health issue.

> But what is misinformation? Is it misinformation to say that bananas are not natural and that they are radioactive?

> What we discovered with Lucile's story is that the notion of misinformation is in fact annoyingly subtle[^reality-game]. On the one hand, it's not quite a fake news as some would say. But on the other hand, said in the wrong context, this sentence can be misleading for some audiences, if they are then led to believe that bananas are therefore dangerous, or that it is better to stay away from them[^fake-problem].
To be clear, yes, bananas have been modified by agriculture. For 7000 years we have been selecting the banana varieties that suit us, it is not natural at all. But this is the case with almost all the food we eat, from wheat to beef, apples, oranges and yes, bananas too. And yes, bananas are radioactive too. But the radioactivity of a banana is two hundred times less than what you get if you take a plane for a 6 hour trip, just because the plane is flying a little high in the sky. If you are afraid of the radioactivity of the banana, you should be terrified of the plane. By the way, there is a unit, the BED, for "banana equivalent dose", which is used in a didactic way to present some very low exposure to radioactivity[^radioactivite-veritasium].

[^reality-game]: [**Book.** The Reality Game How the Next Wave of Technology Will Break the Truth. Samuel Woolley. PublicAffairs (2020).](https://www.publicaffairsbooks.com/titles/samuel-woolley/the-reality-game/9781541768253/)

[^fake-problem]: [**Paper.** Teaching beyond verifying sources and “fake news”: Critical media education to challenge media injustices. Jeremy Stoddard, Jonathan Tunstall, Leila Walker & Emily Wight. Journal of Media Literacy Education (2021).](https://digitalcommons.uri.edu/jmle/vol13/iss2/5/)

[^radioactivite-veritasium]: [**Video.** The Most Radioactive Places on Earth. Veritasium (2014).](https://www.youtube.com/watch?v=TRL7o2kPqw00)

> Unfortunately, as an educational YouTuber, I can assure you that explaining all this takes time[^brandolini]...

[^brandolini]: "Brandolini's law", also known as the principle of asymmetry of idiocy, asserts that the cost of deconstructing an erroneous belief is orders of magnitude greater than the cosf of spreading the erroneous belief. This makes the rectification of erroneous beliefs extremely difficult, especially when confronted with the piling of shaky arguments in defense of a belief.  

> Yes, and the public's attention is very limited. That's why, rather than inundating SmartPoop users with complex information, we've opted to give them only very simple and reliable information, while adding links to more complete information.

> Now for the big announcement in this video. Marc, you are now my boss.

> Yes indeed. Science4Alpha, you are an exceptional educator, who supported us very early in our approach, and who is yourself very concerned by public health issues. We have decided to officially support your work by guaranteeing you a stable income. And we've made similar agreements with nine other science YouTubers. We are very excited about these partnerships because we believe that quality information is a priority for public health[^partnership].

[^partnership]: The appropriateness of such collaborations, with private or government institutions, is an ongoing dilemma for science communication, especially knowing how little funding it receives at the moment, and how difficult it is to access information internal to large companies. One example is this collaboration between science YouTuber SmarterEveryDay and 23AndMe, which is a collaboration framework that the science YouTuber found satisfactory.  
[**Video.** DNA Testing and Privacy (Behind the scenes at the 23andMe Lab) - Smarter Every Day (2017).](https://www.youtube.com/watch?v=U3EEmVfbKNs)  
Especially on controversial topics, such collaborations can have counterproductive effects on trust in science communicators.  
[**Paper.** Trust in scientists in times of pandemic: Panel evidence from 12 countries. Yann Algan, Daniel Cohen, Eva Davoine, Martial Foucault & Stefanie Stantcheva. PNAS (2021).](https://www.pnas.org/content/118/40/e2108576118.abstract)  
For example, Lê Nguyên Hoang, one of the authors of this book, produced a video in collaboration with the French Ministry of Health, which received more dislikes than likes, thus questioning the relevance of such a collaboration.  
[**Video.** Un vaccin pour permettre aux étudiants de retrouver leur vie d'avant (ft. Prof. Fischer). Science4All (2021).](https://www.youtube.com/watch?v=An6YcC7wmUE&list=PLtzmb84AoqRS0SN8VKvAxuGOdcINPRugV&index=13)

> But, Marc, as some are probably writing in the comments, aren't there risks of conflicts of interest?

> Always. We have done our best to find a system that allows you to keep a close eye on us and live comfortably, while guaranteeing you the freedom that scientific communication work requires, especially on sensitive subjects such as public health. In particular, we have committed to guaranteeing one year's income in case of breach of contract with you or your colleagues[^google-ethics], and we have no right of control over the content you publish[^google-approval].

[^google-ethics]: Employees of Google's AI ethics team did not have that luxury. In particular, Timnit Gebru was fired on vacation, without notice, shortly after she wrote an academic research paper critical of the language algorithms in which Google had invested heavily.  
[Science4All (2020).](https://www.youtube.com/watch?v=Ddr-BZ9W180)

[^google-approval]: Note that this is not the case for Google's AI ethics researchers, whose publications are subject to internal approval by senior Google managers. As we saw with the dismissals of Timnit Gebru and Margarett Mitchell, this lack of independence between ethics and Google management is a serious risk to the integrity of Google's research.  
[**Video.** Google is dismantling its ethics (and nobody cares...). Science4All (2021).](https://www.youtube.com/watch?v=HbFadtOxs4k)

> Do you hear that, dear viewers? I promise, I will remain free in what I say. If SmartPoop screws up its product or its new interface, and nevertheless deploys it at scale, I'll be the first to report it.

> I hope so, yes. Our relationship with you is going to be very much based on trust. We trust you, and your willingness to prioritize public health in your videos, over, say, clickbaitness. And we hope that you, Science4Alpha, as well as the general public and our various partners, will trust our commitment to public health above all[^trust].

[^trust]: One of the great difficulties of such a partnership, especially for companies or governments, is trust in the scientific communicator. The communicator could be paid by competitors to produce harmful misinformation. Unfortunately, setting up such partnerships is complicated...

> Shall we take a little selfie with a check to finish this video? And yes, we avoid shaking hands, because we still don't have the guarantee that the ROVID-19 is completely gone. So, thanks Marc, and to you viewers, I hope you're as excited as I am to get a view inside SmartPoop. Of course, I won't be able to tell you everything, because some subjects are sensitive, and there are even stories of insider trading that I prefer to avoid[^transparency]. But I promise, we won't be soft on Marc and Katia, especially if they slip up.

[^transparency]: Transparency is a complicated subject too...

> We'll try not to slip up too much then!

> To make sure you don't miss future videos on public health and algorithmic challenges, don't forget to subscribe, set the bell and feel free to share this video. And I'll see you soon, on Science4Alpha.


## To go further

Don't stop there!
Check [the sequel of the novel](3-bias.md) or the [outline](README.md).  
If you enjoyed it, please consider sharing and promoting this science fiction novel to others!

